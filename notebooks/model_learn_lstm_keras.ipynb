{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74l7lcFQk4kT"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixh2Tyl1FHaj"
   },
   "source": [
    "In this first cell we''ll load the necessary libraries and setup some logging and display options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaCENoitkiXK"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0gBz25Glf-3"
   },
   "source": [
    "Next we'll load our flow variables and time tendency forcings datasets into Xarray Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cC_-nNSlWIO"
   },
   "outputs": [],
   "source": [
    "ds_h0 = xr.open_dataset('C:/home/cam_learn/fv091x180L26_dry_HS.cam.h0.2000-12-27-00000_lowres.nc', decode_times=False)\n",
    "ds_h1 = xr.open_dataset('C:/home/cam_learn/fv091x180L26_dry_HS.cam.h1.2000-12-27-00000_lowres.nc', decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.info of <xarray.Dataset>\n",
       "Dimensions:       (ilev: 27, lat: 12, lev: 26, lon: 23, nbnd: 2, slat: 90, slon: 180, time: 720)\n",
       "Coordinates:\n",
       "  * ilev          (ilev) float64 2.194 4.895 9.882 18.05 29.84 44.62 61.61 ...\n",
       "  * lat           (lat) float64 -90.0 -74.0 -58.0 -42.0 -26.0 -10.0 6.0 22.0 ...\n",
       "  * lev           (lev) float64 3.545 7.389 13.97 23.94 37.23 53.11 70.06 ...\n",
       "  * lon           (lon) float64 0.0 16.0 32.0 48.0 64.0 80.0 96.0 112.0 ...\n",
       "  * slat          (slat) float64 -89.0 -87.0 -85.0 -83.0 -81.0 -79.0 -77.0 ...\n",
       "  * slon          (slon) float64 -1.0 1.0 3.0 5.0 7.0 9.0 11.0 13.0 15.0 ...\n",
       "  * time          (time) float64 0.0 0.02083 0.04167 0.0625 0.08333 0.1042 ...\n",
       "Dimensions without coordinates: nbnd\n",
       "Data variables:\n",
       "    P0            float64 ...\n",
       "    PS            (time, lat, lon) float32 ...\n",
       "    T             (time, lev, lat, lon) float32 ...\n",
       "    U             (time, lev, lat, lon) float32 ...\n",
       "    V             (time, lev, lat, lon) float32 ...\n",
       "    ch4vmr        (time) float64 ...\n",
       "    co2vmr        (time) float64 ...\n",
       "    date          (time) int32 ...\n",
       "    date_written  (time) |S8 ...\n",
       "    datesec       (time) int32 ...\n",
       "    f11vmr        (time) float64 ...\n",
       "    f12vmr        (time) float64 ...\n",
       "    gw            (lat) float64 ...\n",
       "    hyai          (ilev) float64 ...\n",
       "    hyam          (lev) float64 ...\n",
       "    hybi          (ilev) float64 ...\n",
       "    hybm          (lev) float64 ...\n",
       "    mdt           int32 ...\n",
       "    n2ovmr        (time) float64 ...\n",
       "    nbdate        int32 ...\n",
       "    nbsec         int32 ...\n",
       "    ndbase        int32 ...\n",
       "    ndcur         (time) int32 ...\n",
       "    nlon          (lat) int32 ...\n",
       "    nsbase        int32 ...\n",
       "    nscur         (time) int32 ...\n",
       "    nsteph        (time) int32 ...\n",
       "    ntrk          int32 ...\n",
       "    ntrm          int32 ...\n",
       "    ntrn          int32 ...\n",
       "    sol_tsi       (time) float64 ...\n",
       "    time_bnds     (time, nbnd) float64 ...\n",
       "    time_written  (time) |S8 ...\n",
       "    w_stag        (slat) float64 ...\n",
       "    wnummax       (lat) int32 ...\n",
       "Attributes:\n",
       "    Conventions:      CF-1.0\n",
       "    source:           CAM\n",
       "    case:             fv091x180L26_dry_HS\n",
       "    title:            CAM5-FV 2x2L26, dry HS\n",
       "    logname:          cjablono\n",
       "    host:             r1i3n29\n",
       "    Version:          $Name$\n",
       "    revision_Id:      $Id$\n",
       "    initial_file:     /glade2/scratch2/cjablono/fv091x180L26_dry_HS/fv091x180...\n",
       "    topography_file:  /glade/p/work/cjablono/dycore_initial_data/dcmip_james/...\n",
       "    history:          Fri Jul 13 04:01:48 2018: C:\\home\\miniconda3\\Library\\bi...\n",
       "    NCO:              netCDF Operators version 4.7.5 (Homepage = http://nco.s...>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_h0.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.info of <xarray.Dataset>\n",
       "Dimensions:       (ilev: 27, lat: 12, lev: 26, lon: 23, nbnd: 2, slat: 90, slon: 180, time: 720)\n",
       "Coordinates:\n",
       "  * ilev          (ilev) float64 2.194 4.895 9.882 18.05 29.84 44.62 61.61 ...\n",
       "  * lat           (lat) float64 -90.0 -74.0 -58.0 -42.0 -26.0 -10.0 6.0 22.0 ...\n",
       "  * lev           (lev) float64 3.545 7.389 13.97 23.94 37.23 53.11 70.06 ...\n",
       "  * lon           (lon) float64 0.0 16.0 32.0 48.0 64.0 80.0 96.0 112.0 ...\n",
       "  * slat          (slat) float64 -89.0 -87.0 -85.0 -83.0 -81.0 -79.0 -77.0 ...\n",
       "  * slon          (slon) float64 -1.0 1.0 3.0 5.0 7.0 9.0 11.0 13.0 15.0 ...\n",
       "  * time          (time) float64 0.0 0.02083 0.04167 0.0625 0.08333 0.1042 ...\n",
       "Dimensions without coordinates: nbnd\n",
       "Data variables:\n",
       "    P0            float64 ...\n",
       "    PTTEND        (time, lev, lat, lon) float32 ...\n",
       "    PUTEND        (time, lev, lat, lon) float32 ...\n",
       "    PVTEND        (time, lev, lat, lon) float32 ...\n",
       "    ch4vmr        (time) float64 ...\n",
       "    co2vmr        (time) float64 ...\n",
       "    date          (time) int32 ...\n",
       "    date_written  (time) |S8 ...\n",
       "    datesec       (time) int32 ...\n",
       "    f11vmr        (time) float64 ...\n",
       "    f12vmr        (time) float64 ...\n",
       "    gw            (lat) float64 ...\n",
       "    hyai          (ilev) float64 ...\n",
       "    hyam          (lev) float64 ...\n",
       "    hybi          (ilev) float64 ...\n",
       "    hybm          (lev) float64 ...\n",
       "    mdt           int32 ...\n",
       "    n2ovmr        (time) float64 ...\n",
       "    nbdate        int32 ...\n",
       "    nbsec         int32 ...\n",
       "    ndbase        int32 ...\n",
       "    ndcur         (time) int32 ...\n",
       "    nlon          (lat) int32 ...\n",
       "    nsbase        int32 ...\n",
       "    nscur         (time) int32 ...\n",
       "    nsteph        (time) int32 ...\n",
       "    ntrk          int32 ...\n",
       "    ntrm          int32 ...\n",
       "    ntrn          int32 ...\n",
       "    sol_tsi       (time) float64 ...\n",
       "    time_bnds     (time, nbnd) float64 ...\n",
       "    time_written  (time) |S8 ...\n",
       "    w_stag        (slat) float64 ...\n",
       "    wnummax       (lat) int32 ...\n",
       "Attributes:\n",
       "    Conventions:      CF-1.0\n",
       "    source:           CAM\n",
       "    case:             fv091x180L26_dry_HS\n",
       "    title:            CAM5-FV 2x2L26, dry HS\n",
       "    logname:          cjablono\n",
       "    host:             r1i3n29\n",
       "    Version:          $Name$\n",
       "    revision_Id:      $Id$\n",
       "    initial_file:     /glade2/scratch2/cjablono/fv091x180L26_dry_HS/fv091x180...\n",
       "    topography_file:  /glade/p/work/cjablono/dycore_initial_data/dcmip_james/...\n",
       "    history:          Fri Jul 13 04:02:27 2018: C:\\home\\miniconda3\\Library\\bi...\n",
       "    NCO:              netCDF Operators version 4.7.5 (Homepage = http://nco.s...>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_h1.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the time variable in order to work out the initial date, number of steps, units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.IndexVariable 'time' (time: 720)>\n",
       "array([ 0.      ,  0.020833,  0.041667, ..., 14.9375  , 14.958333, 14.979167])\n",
       "Attributes:\n",
       "    long_name:  time\n",
       "    units:      days since 2000-12-27 00:00:00\n",
       "    calendar:   noleap\n",
       "    bounds:     time_bnds"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_h0.variables['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we have the same time values for the targets data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ds_h0.variables['time'].values != ds_h1.variables['time'].values).any():\n",
    "    print('ERROR: Non-matching time values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create array of datetime values from the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2000-12-27 00:00:00\n",
       "1     2000-12-27 00:30:00\n",
       "2     2000-12-27 01:00:00\n",
       "3     2000-12-27 01:30:00\n",
       "4     2000-12-27 02:00:00\n",
       "              ...        \n",
       "715   2001-01-10 21:30:00\n",
       "716   2001-01-10 22:00:00\n",
       "717   2001-01-10 22:30:00\n",
       "718   2001-01-10 23:00:00\n",
       "719   2001-01-10 23:30:00\n",
       "Length: 720, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = ds_h0.variables['time'].values.flatten()\n",
    "initial = datetime(2000, 12, 27)\n",
    "datetimes = np.empty(shape=times.shape, dtype='datetime64[m]')\n",
    "for i in range(datetimes.size):\n",
    "    datetimes[i] = initial + timedelta(days=times[i])\n",
    "timestamps = pd.Series(datetimes)\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As features we'll use the following flow variables:\n",
    "\n",
    "* U (west-east (zonal) wind, m/s)\n",
    "* V (south-north (meridional) wind, m/s)\n",
    "* T (temperature, K)\n",
    "* PS (surface pressure, Pa)\n",
    "\n",
    "Time tendency forcings are the targets (labels) that our model should learn to predict.\n",
    "\n",
    "* PTTEND (time tendency of the temperature)\n",
    "* PUTEND (time tendency of the zonal wind)\n",
    "* PVTEND (time tendency of the meridional wind)\n",
    "\n",
    "For the first lat, lon, and level we'll get all time steps for the feature variables. We'll do the same for the label variables PTTEND, PUTEND, and PVTEND."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = pd.Series(ds_h0.variables['PS'].values[:, 0, 0])\n",
    "t = pd.Series(ds_h0.variables['T'].values[:, 0, 0, 0])\n",
    "u = pd.Series(ds_h0.variables['U'].values[:, 0, 0, 0])\n",
    "v = pd.Series(ds_h0.variables['V'].values[:, 0, 0, 0])\n",
    "pttend = pd.Series(ds_h1.variables['PTTEND'].values[:, 0, 0, 0])\n",
    "putend = pd.Series(ds_h1.variables['PUTEND'].values[:, 0, 0, 0])\n",
    "pvtend = pd.Series(ds_h1.variables['PVTEND'].values[:, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a Pandas DataFrame containing inputs (features) and output (label/target) for use when predicting temperature time tendencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PS</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>PTTEND</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-27 00:00:00</th>\n",
       "      <td>101099.06</td>\n",
       "      <td>210.86</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 00:30:00</th>\n",
       "      <td>101108.92</td>\n",
       "      <td>210.86</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 01:00:00</th>\n",
       "      <td>101118.48</td>\n",
       "      <td>210.86</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 01:30:00</th>\n",
       "      <td>101127.91</td>\n",
       "      <td>210.86</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 02:00:00</th>\n",
       "      <td>101137.39</td>\n",
       "      <td>210.86</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PS      T     U     V  PTTEND\n",
       "timestamp                                               \n",
       "2000-12-27 00:00:00 101099.06 210.86 -0.81 -0.28   -0.00\n",
       "2000-12-27 00:30:00 101108.92 210.86 -0.82 -0.30   -0.00\n",
       "2000-12-27 01:00:00 101118.48 210.86 -0.83 -0.32   -0.00\n",
       "2000-12-27 01:30:00 101127.91 210.86 -0.83 -0.33   -0.00\n",
       "2000-12-27 02:00:00 101137.39 210.86 -0.83 -0.35   -0.00"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame({'timestamp': timestamps,\n",
    "                         'PS': ps,\n",
    "                         'T': t,\n",
    "                         'U': u,\n",
    "                         'V': v,\n",
    "                         'PTTEND': pttend})\n",
    "df_temp.set_index('timestamp', inplace=True)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 720 entries, 2000-12-27 00:00:00 to 2001-01-10 23:30:00\n",
      "Data columns (total 5 columns):\n",
      "PS        720 non-null float32\n",
      "T         720 non-null float32\n",
      "U         720 non-null float32\n",
      "V         720 non-null float32\n",
      "PTTEND    720 non-null float32\n",
      "dtypes: float32(5)\n",
      "memory usage: 19.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that will frame the time series as a supervised learning problem set (described [here](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_supervised(df,\n",
    "                          previous_steps=1, \n",
    "                          forecast_steps=1,\n",
    "                          dropnan=True):\n",
    "\n",
    "    # original column names\n",
    "    col_names = df.columns\n",
    "    \n",
    "    # list of columns and corresponding names we'll build from \n",
    "    # the originals found in the input DataFrame\n",
    "    cols, names = list(), list()\n",
    "\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(previous_steps, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (col_name, i)) for col_name in col_names]\n",
    "\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, forecast_steps):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('%s(t)' % col_name) for col_name in col_names]\n",
    "        else:\n",
    "            names += [('%s(t+%d)' % (col_name, i)) for col_name in col_names]\n",
    "\n",
    "    # put all the columns together into a single aggregated DataFrame\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the feature variables using scikit-learn's MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50631714, 1.        , 0.22656655, 0.69448346, 0.        ],\n",
       "       [0.5129471 , 0.9949341 , 0.22496124, 0.68799436, 0.00498581],\n",
       "       [0.51937866, 0.98950195, 0.2233897 , 0.6815935 , 0.01043701],\n",
       "       ...,\n",
       "       [0.12479401, 0.23565674, 0.98422444, 0.7495539 , 0.76434326],\n",
       "       [0.12210846, 0.23876953, 0.98267317, 0.7519671 , 0.76122856],\n",
       "       [0.11936951, 0.2397461 , 0.98426366, 0.7531688 , 0.76023674]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(df_temp.values)\n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the original columns with the scaled values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PS</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>PTTEND</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-27 00:00:00</th>\n",
       "      <td>0.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 00:30:00</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 01:00:00</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 01:30:00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 02:00:00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PS    T    U    V  PTTEND\n",
       "timestamp                                      \n",
       "2000-12-27 00:00:00 0.51 1.00 0.23 0.69    0.00\n",
       "2000-12-27 00:30:00 0.51 0.99 0.22 0.69    0.00\n",
       "2000-12-27 01:00:00 0.52 0.99 0.22 0.68    0.01\n",
       "2000-12-27 01:30:00 0.53 0.98 0.22 0.68    0.02\n",
       "2000-12-27 02:00:00 0.53 0.98 0.22 0.67    0.02"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df_temp.columns)):\n",
    "    s = pd.Series(scaled[:, i])\n",
    "    df_temp[df_temp.columns[i]] = s.values\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame the variables as a supervised learning problem (as described [here](https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PS(t-1)</th>\n",
       "      <th>T(t-1)</th>\n",
       "      <th>U(t-1)</th>\n",
       "      <th>V(t-1)</th>\n",
       "      <th>PTTEND(t-1)</th>\n",
       "      <th>PS(t)</th>\n",
       "      <th>T(t)</th>\n",
       "      <th>U(t)</th>\n",
       "      <th>V(t)</th>\n",
       "      <th>PTTEND(t)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-27 00:30:00</th>\n",
       "      <td>0.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 01:00:00</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 01:30:00</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 02:00:00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-27 02:30:00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PS(t-1)  T(t-1)  U(t-1)  V(t-1)  PTTEND(t-1)  PS(t)  \\\n",
       "timestamp                                                                  \n",
       "2000-12-27 00:30:00     0.51    1.00    0.23    0.69         0.00   0.51   \n",
       "2000-12-27 01:00:00     0.51    0.99    0.22    0.69         0.00   0.52   \n",
       "2000-12-27 01:30:00     0.52    0.99    0.22    0.68         0.01   0.53   \n",
       "2000-12-27 02:00:00     0.53    0.98    0.22    0.68         0.02   0.53   \n",
       "2000-12-27 02:30:00     0.53    0.98    0.22    0.67         0.02   0.54   \n",
       "\n",
       "                     T(t)  U(t)  V(t)  PTTEND(t)  \n",
       "timestamp                                         \n",
       "2000-12-27 00:30:00  0.99  0.22  0.69       0.00  \n",
       "2000-12-27 01:00:00  0.99  0.22  0.68       0.01  \n",
       "2000-12-27 01:30:00  0.98  0.22  0.68       0.02  \n",
       "2000-12-27 02:00:00  0.98  0.22  0.67       0.02  \n",
       "2000-12-27 02:30:00  0.98  0.22  0.67       0.02  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed = convert_to_supervised(df_temp, 1, 1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns for variables we won't use as features or targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.drop(columns=['PS(t)', 'T(t)', 'U(t)', 'V(t)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 719 entries, 2000-12-27 00:30:00 to 2001-01-10 23:30:00\n",
      "Data columns (total 6 columns):\n",
      "PS(t-1)        719 non-null float32\n",
      "T(t-1)         719 non-null float32\n",
      "U(t-1)         719 non-null float32\n",
      "V(t-1)         719 non-null float32\n",
      "PTTEND(t-1)    719 non-null float32\n",
      "PTTEND(t)      719 non-null float32\n",
      "dtypes: float32(6)\n",
      "memory usage: 22.5 KB\n"
     ]
    }
   ],
   "source": [
    "reframed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-yXL6dZMWjP"
   },
   "source": [
    "## Split the data into training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApCinhR8__SL"
   },
   "source": [
    "For simplicity we'll start with an even split of 50% for training and 50% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6waMx-cMg71"
   },
   "outputs": [],
   "source": [
    "# the values array is 719 rows x 10 columns\n",
    "train = reframed.values[:360, :]   # rows 0 - 359\n",
    "test = reframed.values[360:, :]   # rows 360 - 719\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00498581, 0.01043701, 0.01571846, 0.02043343, 0.02449036,\n",
       "       0.02793884, 0.03071404, 0.03261375, 0.03356171, 0.0336895 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00498581 0.01043701 0.01571846 0.02043343 0.02449036 0.02793884\n",
      " 0.03071404 0.03261375 0.03356171 0.0336895 ]\n"
     ]
    }
   ],
   "source": [
    "x = reframed['PTTEND(t)'].values[:10]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHEqkPkjCPDm"
   },
   "source": [
    "## Create the neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUHTM6yaDzZV"
   },
   "source": [
    "Next, we'll instantiate and configure a neural network using TensorFlow's [DNNRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor) class. We'll train this model using the GradientDescentOptimizer, which implements Mini-Batch Stochastic Gradient Descent (SGD). The learning_rate argument controls the size of the gradient step.\n",
    "\n",
    "NOTE: To be safe, we also apply gradient clipping to our optimizer via `clip_gradients_by_norm`. Gradient clipping ensures the magnitude of the gradients do not become too large during training, which can cause gradient descent to fail.\n",
    "\n",
    "We use `hidden_units`to define the structure of the NN. The `hidden_units` argument provides a list of ints, where each int corresponds to a hidden layer and indicates the number of nodes in it. For example, consider the following assignment:\n",
    "\n",
    "`hidden_units=[3, 10]`\n",
    "\n",
    "The preceding assignment specifies a neural net with two hidden layers:\n",
    "\n",
    "The first hidden layer contains 3 nodes.\n",
    "The second hidden layer contains 10 nodes.\n",
    "If we wanted to add more layers, we'd add more ints to the list. For example, `hidden_units=[10, 20, 30, 40]` would create four layers with ten, twenty, thirty, and forty units, respectively.\n",
    "\n",
    "By default, all hidden layers will use ReLu activation and will be fully connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cmvlnh4uC9SS"
   },
   "outputs": [],
   "source": [
    "# Use gradient descent as the optimizer for training the model.\n",
    "gd_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "gd_optimizer = tf.contrib.estimator.clip_gradients_by_norm(gd_optimizer, 5.0)\n",
    "\n",
    "# Use two hidden layers with 3 and 10 nodes each.\n",
    "hidden_units=[3, 10]\n",
    "\n",
    "# Instantiate the neural network.\n",
    "dnn_regressor = tf.estimator.DNNRegressor(feature_columns=feature_columns,\n",
    "                                          hidden_units=hidden_units,\n",
    "                                          optimizer=gd_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1CRW1a0Ds1C"
   },
   "source": [
    "## Define the input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhyUxyMoF0wQ"
   },
   "source": [
    "To import our weather data into our DNNRegressor, we need to define an input function, which instructs TensorFlow how to preprocess the data, as well as how to batch, shuffle, and repeat it during model training.\n",
    "\n",
    "First, we'll convert our xarray feature data into a dict of NumPy arrays. We can then use the TensorFlow Dataset API to construct a dataset object from our data, and then break our data into batches of `batch_size`, to be repeated for the specified number of epochs (`num_epochs`).\n",
    "\n",
    "NOTE: When the default value of `num_epochs=None` is passed to `repeat()`, the input data will be repeated indefinitely.\n",
    "\n",
    "Next, if `shuffle` is set to True, we'll shuffle the data so that it's passed to the model randomly during training. The `buffer_size` argument specifies the size of the dataset from which shuffle will randomly sample.\n",
    "\n",
    "Finally, our input function constructs an iterator for the dataset and returns the next batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZiWqTxvGNJO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "def get_input(features, \n",
    "              targets, \n",
    "              batch_size=1, \n",
    "              shuffle=True, \n",
    "              num_epochs=None):\n",
    "    \"\"\"\n",
    "    Extracts a batch of elements from a dataset.\n",
    "  \n",
    "    Args:\n",
    "      features: xarray Dataset of features\n",
    "      targets: xarray Dataset of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. \n",
    "                  None == repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "  \n",
    "    # Convert xarray data into a dict of numpy arrays.\n",
    "    features_dict = {}\n",
    "    for var in features.variables:\n",
    "        # Convert data into a dict of np arrays.\n",
    "        data_array = features[var]\n",
    "        features_dict[var] = data_array.values\n",
    "\n",
    "    targets_dict = {}\n",
    "    for var in targets.variables:\n",
    "        data_array = data_h1[var]\n",
    "        targets_dict[var] = data_array.values\n",
    "\n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features_dict, targets_dict)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels\n",
    "\n",
    "# Create input functions. Wrap get_input() in a lambda so we \n",
    "# can pass in features and targets as arguments.\n",
    "input_training = lambda: get_input(features_training, \n",
    "                                   targets_training, \n",
    "                                   batch_size=10)\n",
    "predict_input_training = lambda: get_input(features_training, \n",
    "                                           targets_training, \n",
    "                                           num_epochs=1, \n",
    "                                           shuffle=False)\n",
    "predict_input_validation = lambda: get_input(features_validation, \n",
    "                                             targets_validation, \n",
    "                                             num_epochs=1, \n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqJj8vtMIbt5"
   },
   "source": [
    "## Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQTKlqSHIgVh"
   },
   "source": [
    "We can now call `train()` on our `dnn_regressor` to train the model. We'll loop over a number of periods and on each loop we'll train the model, use it to make predictions, and compute the RMSE of the loss for both training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "iwfgGEY-I1pR",
    "outputId": "0471a7f1-211b-4412-dd69-61bb8ca2386c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "print(\"RMSE (on training data):\")\n",
    "training_rmse = []\n",
    "validation_rmse = []\n",
    "\n",
    "steps = 500\n",
    "periods = 20\n",
    "steps_per_period = steps / periods\n",
    "\n",
    "# Train the model inside a loop so that we can periodically assess loss metrics.\n",
    "for period in range (0, periods):\n",
    "\n",
    "    # Train the model, starting from the prior state.\n",
    "    dnn_regressor.train(input_fn=input_training,\n",
    "                        steps=steps_per_period)\n",
    "\n",
    "    # Take a break and compute predictions, converting to numpy arrays.\n",
    "    training_predictions = dnn_regressor.predict(input_fn=predict_input_training)\n",
    "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
    "    \n",
    "    validation_predictions = dnn_regressor.predict(input_fn=predict_input_validation)\n",
    "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "    \n",
    "    # Compute training and validation loss.\n",
    "    training_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(training_predictions, targets_training))\n",
    "    validation_root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(validation_predictions, targets_validation))\n",
    "    \n",
    "    # Print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
    "    \n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_rmse.append(training_root_mean_squared_error)\n",
    "    validation_rmse.append(validation_root_mean_squared_error)\n",
    "\n",
    "print(\"Model training finished.\")\n",
    "\n",
    "# Output a graph of loss metrics over periods.\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Periods\")\n",
    "plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "plt.tight_layout()\n",
    "plt.plot(training_rmse, label=\"training\")\n",
    "plt.plot(validation_rmse, label=\"validation\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"Final RMSE (on training data):   %0.2f\" % training_root_mean_squared_error)\n",
    "print(\"Final RMSE (on validation data): %0.2f\" % validation_root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVzN6_fWZDJn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "model_learn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
