{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate modeling with Keras\n",
    "This notebook illustrates the process of creating simple neural network models using the Keras framework, processing data for input to the models for training and prediction, using a scikit-learn Pipeline, and the use of numpy and xarray for data wrangling and I/O with datasets contained within NetCDF files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify NetCDF files used for training and prediciton inputs\n",
    "These are low resolution versions of NCAR CAM inputs/outputs, located in the `example_data` directory of this project's git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/james/git/climate_learn/example_data\"\n",
    "result_dir = \"/home/james/data/test/climate_learn\"\n",
    "\n",
    "# files used as feature inputs for model training\n",
    "netcdf_features_train = data_dir + \"/fv091x180L26_moist_HS.cam.h0.2001-01-11-00000_lowres.nc\"\n",
    "\n",
    "# files used as label inputs for model training\n",
    "netcdf_labels_train = data_dir + \"/fv091x180L26_moist_HS.cam.h1.2001-01-11-00000_lowres.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets for training and prediction\n",
    "\n",
    "We'll define a function to extract an array of variable(s) for a single level from an xarray DataSet, and another to extract both features and labels from NetCDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "def extract_data_array(dataset,\n",
    "                       variables,\n",
    "                       lev):\n",
    "\n",
    "    # allocate the array\n",
    "    arr = np.empty(shape=[dataset.time.size, \n",
    "                          dataset.lat.size, \n",
    "                          dataset.lon.size, \n",
    "                          len(variables)],\n",
    "                   dtype=np.float64)\n",
    "    \n",
    "    # for each variable we'll extract the values \n",
    "    for var_index, var in enumerate(variables):\n",
    "\n",
    "        # if we have (time, lev, lat, lon), then use level parameter\n",
    "        dimensions = dataset.variables[var].dims\n",
    "        if dimensions == ('time', 'lev', 'lat', 'lon'):\n",
    "            values = dataset[var].values[:, lev, :, :]\n",
    "        elif dimensions == ('time', 'lat', 'lon'):\n",
    "            values = dataset[var].values[:, :, :]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported variable dimensions: {dims}\".format(dims=dimensions))\n",
    "\n",
    "        # add the values into the array at the variable's position\n",
    "        arr[:, :, :, var_index] = values\n",
    "    \n",
    "    return arr\n",
    "    \n",
    "    \n",
    "def extract_features_labels(netdcf_features, \n",
    "                            netcdf_labels,\n",
    "                            feature_vars,\n",
    "                            label_vars,\n",
    "                            level=0):\n",
    "    \"\"\"\n",
    "    Extracts feature and label data from specified NetCDF files for a single level as numpy arrays.\n",
    "    \n",
    "    The feature and label NetCDFs are expected to have matching time, level, lat, and lon coordinate variables.\n",
    "    \n",
    "    Returns two arrays: the first for features and the second for labels. Arrays will have shape (time, lat, lon, var),\n",
    "    where var is the number of feature or label variables. For example if the dimensions of feature data variables in \n",
    "    the NetCDF is (time: 360, lev: 26, lat: 120, lon: 180) and the features specified are [\"T\", \"U\"] then the resulting\n",
    "    features array will have shape (360, 120, 180, 2), with the first feature variable \"T\" corresponding to array[:, :, :, 0]\n",
    "    and the second feature variable \"U\" corresponding to array[:, :, :, 1].\n",
    "    \n",
    "    :param netdcf_features: one or more NetCDF files containing feature variables, can be single file or list\n",
    "    :param netdcf_features: one or more NetCDF files containing label variables, can be single file or list\n",
    "    :param feature_vars: list of feature variable names to be extracted from the features NetCDF\n",
    "    :param label_vars: list of label variable names to be extracted from the labels NetCDF\n",
    "    :param level: index of the level to be extracted (all times/lats/lons at this level for each feature/label variable)\n",
    "    :return: two 4-D numpy arrays, the first for features and the second for labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # open the features (flows) and labels (tendencies) as xarray DataSets\n",
    "    ds_features = xr.open_mfdataset(paths=netdcf_features)\n",
    "    ds_labels = xr.open_mfdataset(paths=netcdf_labels)\n",
    "\n",
    "    # confirm that we have datasets that match on the time, lev, lat, and lon dimension/coordinate\n",
    "    if np.any(ds_features.variables['time'].values != ds_labels.variables['time'].values):\n",
    "        raise ValueError('Non-matching time values between feature and label datasets')\n",
    "    if np.any(ds_features.variables['lev'].values != ds_labels.variables['lev'].values):\n",
    "        raise ValueError('Non-matching level values between feature and label datasets')\n",
    "    if np.any(ds_features.variables['lat'].values != ds_labels.variables['lat'].values):\n",
    "        raise ValueError('Non-matching lat values between feature and label datasets')\n",
    "    if np.any(ds_features.variables['lon'].values != ds_labels.variables['lon'].values):\n",
    "        raise ValueError('Non-matching lon values between feature and label datasets')\n",
    "\n",
    "    # extract feature and label arrays at the specified level\n",
    "    array_features = extract_data_array(ds_features, feature_vars, level)\n",
    "    array_labels = extract_data_array(ds_labels, label_vars, level)\n",
    "    \n",
    "    return array_features, array_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare the variables that will be used as features and labels for training and prediction\n",
    "The feature variables being used are 'PS', 'T', 'U', and 'V'. The label variable is 'PTTEND'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"PS\", \"T\", \"U\", \"V\"]\n",
    "labels = [\"PTTEND\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datsets\n",
    "Read NetCDF files to load feature and label datasets that will be used for training.\n",
    "\n",
    "All files should share the same time, level, lat, and lon coordinates, with each file's feature or label variables having shape (times, levels, lats, lons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = extract_features_labels(netcdf_features_train,\n",
    "                                           netcdf_labels_train,\n",
    "                                           features,\n",
    "                                           labels,\n",
    "                                           level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data dimensions\n",
    "Get the dimension sizes of our datasets for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_times_train = train_x.shape[0]\n",
    "size_times_predict = predict_x.shape[0]\n",
    "size_lat = train_x.shape[1]\n",
    "size_lon = train_x.shape[2]\n",
    "size_lev = xr.open_dataset(netcdf_features_predict[0]).lev.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformer\n",
    "\n",
    "Neural network models work much better if all values are scaled into a range such as between 0 and 1. For this purpose we'll use scikit-learn's MinMaxScaler for now within a custom Scaler class that can be used within a scikit-lean Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class Scaler(TransformerMixin):\n",
    "\n",
    "    def __init__(self, features):\n",
    "\n",
    "        # initialize an ordered dict to store scalers for each feature\n",
    "        self.scalers = OrderedDict().fromkeys(features, MinMaxScaler(feature_range=(0, 1)))\n",
    "\n",
    "    def transform(self, values):\n",
    "        \"\"\"\n",
    "        Transforms a 4-D array of values, expected to have shape:\n",
    "        (times, lats, lons, vars).\n",
    "\n",
    "        :param values:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # make new arrays to contain the scaled values we'll return\n",
    "        scaled_features = np.empty(shape=values.shape)\n",
    "\n",
    "        # data is 4-D with shape (times, lats, lons, vars), scalers can only\n",
    "        # work on 2-D arrays, so for each variable we scale the corresponding\n",
    "        # 3-D array of values after flattening it, then reshape back into\n",
    "        # the original shape\n",
    "        var_ix = 0\n",
    "        for variable, scaler in self.scalers.items():\n",
    "            variable = values[:, :, :, var_ix].flatten().reshape(-1, 1)\n",
    "            scaled_feature = scaler.fit_transform(variable)\n",
    "            reshaped_scaled_feature = np.reshape(scaled_feature,\n",
    "                                                 newshape=(values.shape[0],\n",
    "                                                           values.shape[1],\n",
    "                                                           values.shape[2]))\n",
    "            scaled_features[:, :, :, var_ix] = reshaped_scaled_feature\n",
    "            var_ix += 1\n",
    "\n",
    "        # return the scaled values (the scalers have been fitted to the data)\n",
    "        return scaled_features\n",
    "\n",
    "    def fit(self, x=None):\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Keras models to use for prediciton\n",
    "We'll define two neural network models using the Keras library with TensorFlow as its backend. One of these models will contain only simple densely connected layers, and another will contain a both convolutional layer and a densely connected layer. We'll use both of these for prediction of labels corresponding to the results of NCAR CAM model runs involving computation of the Held-Suarez test case. Initially we'll focus on the input feature variables PS, T, U, and V and the output label PTTEND."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layer-only model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 69\n",
      "Trainable params: 69\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define the model\n",
    "dense_model = Sequential()\n",
    "\n",
    "# add a fully-connected hidden layer with the same number of neurons as input attributes (features)\n",
    "dense_model.add(Dense(len(features), input_dim=len(features), activation='relu'))\n",
    "\n",
    "# add a fully-connected hidden layer with the twice the number of neurons as input attributes (features)\n",
    "dense_model.add(Dense(len(features) * 2, activation='relu'))\n",
    "\n",
    "# output layer uses no activation function since we are interested\n",
    "# in predicting numerical values directly without transform\n",
    "dense_model.add(Dense(len(labels)))\n",
    "\n",
    "# compile the model using the ADAM optimization algorithm and a mean squared error loss function\n",
    "dense_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# display some summary information\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolutional layer model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 720, 12, 23, 32)   3488      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 720, 12, 23, 8)    264       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 720, 12, 23, 1)    9         \n",
      "=================================================================\n",
      "Total params: 3,761\n",
      "Trainable params: 3,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, Dense\n",
    "\n",
    "# define the model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# add an initial 3-D convolutional layer\n",
    "cnn_model.add(Conv3D(filters=32,\n",
    "                     kernel_size=(3, 3, 3),\n",
    "                     activation=\"relu\",\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=(size_times_train, size_lat, size_lon, len(features)),\n",
    "                     padding='same'))\n",
    "\n",
    "# add a fully-connected hidden layer with twice the number of neurons as input attributes (features)\n",
    "cnn_model.add(Dense(len(features) * 2, activation='relu'))\n",
    "\n",
    "# output layer uses no activation function since we are interested\n",
    "# in predicting numerical values directly without transform\n",
    "cnn_model.add(Dense(len(labels)))\n",
    "\n",
    "# compile the model using the ADAM optimization algorithm and a mean squared error loss function\n",
    "cnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# display some summary information\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape data for input to convolutional model\n",
    "\n",
    "The convolutional neural network model we've defined above will expect input data arrays to have shape (1, times, lats, lons, features) so we'll reshape the training and prediction input arrays using `numpy.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = (1, ) + scaled_train_x.shape\n",
    "shape_y = (1, ) + scaled_train_y.shape\n",
    "train_x_cnn = np.reshape(scaled_train_x, newshape=shape_x)\n",
    "train_y_cnn = np.reshape(scaled_train_y, newshape=shape_y)\n",
    "predict_x_cnn = np.reshape(scaled_predict_x, newshape=shape_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the CNN model\n",
    "We'll now train the convolutional neural network model using the first level of data from the dataset, to confirm that the model is working as expected in terms of being able to perform training to our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 4s - loss: 0.0377\n",
      "Epoch 2/3\n",
      " - 4s - loss: 0.0350\n",
      "Epoch 3/3\n",
      " - 4s - loss: 0.0351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68ac809a58>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(train_x_cnn, train_y_cnn, shuffle=True, epochs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape data for dense model input\n",
    "The dense layer neural network model we've defined above will expect input data arrays to have shape (times * lats * lons, features) so we'll reshape the training and prediction input arrays using `numpy.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = (size_times_train * size_lat * size_lon, len(features))\n",
    "shape_y = (size_times_train * size_lat * size_lon, len(labels))\n",
    "train_x_dense = np.reshape(scaled_train_x, newshape=shape_x)\n",
    "train_y_dense = np.reshape(scaled_train_y, newshape=shape_y)\n",
    "predict_x_dense = np.reshape(scaled_predict_x, newshape=shape_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the dense layers model\n",
    "We'll now train the dense layers neural network model using the first level of data from the dataset, to confirm that the model is working as expected in terms of being able to perform training to our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 10s - loss: 1.7229e-07\n",
      "Epoch 2/3\n",
      " - 9s - loss: 1.7222e-07\n",
      "Epoch 3/3\n",
      " - 7s - loss: 1.7521e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f682c10f2e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model.fit(train_x_dense, train_y_dense, shuffle=True, epochs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline testing\n",
    "Create and use a scikit-learn Pipeline for fitting, prediction, and parameter scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', Scaler(args.feature_names)),\n",
    "    ('model', create_dense_model()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Testing score: ', pipeline.score(X_test, y_test))\n",
    "y_predict = pipeline.predict(X_test)\n",
    "\n",
    "param_to_test_0 = np.arange(1, 11)\n",
    "param_to_test_1 = 2.0 ** np.arange(-6, +6)\n",
    "params = {'param_0': param_to_test_0,\n",
    "          'param_1': param_to_test_1}\n",
    "grid_search = GridSearchCV(pipeline, params, verbose=1).fit(X_train, y_train)\n",
    "print('Final score is: ', grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocate arrays to contain predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cnn = np.empty(shape=(size_times_predict, size_lev, size_lat, size_lon))\n",
    "prediction_dense = np.empty(shape=(size_times_predict, size_lev, size_lat, size_lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform prediction using the fitted models\n",
    "Below we'll perform predictions using the fitted models to confirm that they are properly setup for this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 359ms/step\n",
      "198720/198720 [==============================] - 4s 19us/step\n"
     ]
    }
   ],
   "source": [
    "predict_y_scaled_cnn = cnn_model.predict(predict_x_cnn, verbose=1)\n",
    "predict_y_scaled_dense = dense_model.predict(predict_x_dense, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display some attributes of the predicted values\n",
    "We'll get some attributes of the predicted arrays to demonstrate that the models produced expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model's prediction array shape: (1, 720, 12, 23, 1)\n",
      "Dense model's prediction array shape: (198720, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN model's prediction array shape: {shape}\".format(shape=predict_y_scaled_cnn.shape))\n",
    "print(\"Dense model's prediction array shape: {shape}\".format(shape=predict_y_scaled_dense.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('scaler', Scaler(args.feature_names)),\n",
    "        ('model', create_dense_model()),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print('Testing score: ', pipeline.score(X_test, y_test))\n",
    "    y_predict = pipeline.predict(X_test)\n",
    "\n",
    "    param_to_test_0 = np.arange(1, 11)\n",
    "    param_to_test_1 = 2.0 ** np.arange(-6, +6)\n",
    "    params = {'param_0': param_to_test_0,\n",
    "              'param_1': param_to_test_1}\n",
    "    grid_search = GridSearchCV(pipeline, params, verbose=1).fit(X_train, y_train)\n",
    "    print('Final score is: ', grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction loop\n",
    "We'll loop over each level, taking data for the full grid at that level (all time steps) and training the model with those feature and labels. We'll then use the fitted model to predict label values for the level using input feature values from a different time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/predicting for level 0\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.0368\n",
      "Epoch 2/3\n",
      " - 4s - loss: 0.0384\n",
      "Epoch 3/3\n",
      " - 4s - loss: 0.0391\n",
      "Epoch 1/3\n",
      " - 8s - loss: 1.6340e-07\n",
      "Epoch 2/3\n",
      " - 7s - loss: 1.6436e-07\n",
      "Epoch 3/3\n",
      " - 7s - loss: 1.6870e-07\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "198720/198720 [==============================] - 4s 18us/step\n",
      "Training/predicting for level 1\n",
      "Epoch 1/3\n",
      " - 4s - loss: 0.0576\n",
      "Epoch 2/3\n",
      " - 4s - loss: 0.0569\n",
      "Epoch 3/3\n",
      " - 4s - loss: 0.0557\n",
      "Epoch 1/3\n",
      " - 7s - loss: 2.1017e-07\n",
      "Epoch 2/3\n",
      " - 9s - loss: 1.7951e-07\n",
      "Epoch 3/3\n"
     ]
    }
   ],
   "source": [
    "# loop over all levels\n",
    "for lev in range(size_lev):\n",
    "    \n",
    "    print(\"Training/predicting for level {level}\".format(level=lev))\n",
    "    \n",
    "    # get the features and labels for training\n",
    "    train_x, train_y = extract_features_labels(netcdf_features_train[0],\n",
    "                                               netcdf_labels_train[0],\n",
    "                                               features,\n",
    "                                               labels,\n",
    "                                               lev)\n",
    "    \n",
    "    # get the features for prediction\n",
    "    predict_x = extract_data_array(xr.open_dataset(netcdf_features_predict[0]),\n",
    "                                   features,\n",
    "                                   lev)\n",
    "\n",
    "    # scale the data between 0 and 1\n",
    "    scalers_x = [MinMaxScaler(feature_range=(0, 1))] * len(features)\n",
    "    scalers_y = [MinMaxScaler(feature_range=(0, 1))] * len(labels)\n",
    "    scaled_train_x, scaled_predict_x, scaled_train_y, scalers_x, scalers_y = \\\n",
    "        scale_4d(train_x, predict_x, train_y, scalers_x, scalers_y)\n",
    "    \n",
    "    # reshape the data for convolutional model input\n",
    "    shape_x = (1, ) + scaled_train_x.shape\n",
    "    shape_y = (1, ) + scaled_train_y.shape\n",
    "    train_x_cnn = np.reshape(scaled_train_x, newshape=shape_x)\n",
    "    train_y_cnn = np.reshape(scaled_train_y, newshape=shape_y)\n",
    "    predict_x_cnn = np.reshape(scaled_predict_x, newshape=shape_x)\n",
    "    \n",
    "    # reshape the data for dense layer model input\n",
    "    shape_x = (size_times_train * size_lat * size_lon, len(features))\n",
    "    shape_y = (size_times_train * size_lat * size_lon, len(labels))\n",
    "    train_x_dense = np.reshape(scaled_train_x, newshape=shape_x)\n",
    "    train_y_dense = np.reshape(scaled_train_y, newshape=shape_y)\n",
    "    predict_x_dense = np.reshape(scaled_predict_x, newshape=shape_x)\n",
    "    \n",
    "    # train the models\n",
    "    cnn_model.fit(train_x_cnn, train_y_cnn, shuffle=True, epochs=3, verbose=2)\n",
    "    dense_model.fit(train_x_dense, train_y_dense, shuffle=True, epochs=3, verbose=2)\n",
    "    \n",
    "    # use the fitted models to make predictions\n",
    "    predict_y_scaled_cnn = cnn_model.predict(predict_x_cnn, verbose=1)\n",
    "    predict_y_scaled_dense = dense_model.predict(predict_x_dense, verbose=1)\n",
    "\n",
    "    # reverse the scaling of the predicted values\n",
    "    # TODO below assumes a single label, will need modification for multiple labels\n",
    "    scaler = scalers_y[0]  # assumes the label scaler was fitted in scale_4d() and side effect carried through\n",
    "        \n",
    "    # output from the dense model is 2-D, good for scaler input\n",
    "    unscaled_predict_y_dense = scaler.inverse_transform(predict_y_scaled_dense)\n",
    "        \n",
    "    # output from CNN model is 5-D, so we'll flatten first to make it amenable to scaling\n",
    "    unscaled_predict_y_cnn = scaler.inverse_transform(predict_y_scaled_cnn.flatten().reshape(-1, 1))\n",
    "    \n",
    "    # reshape data so it's compatible with assignment into prediction arrays\n",
    "    level_shape = (size_times_predict, size_lat, size_lon)\n",
    "    prediction_cnn[:, lev, :, :] = np.reshape(unscaled_predict_y_cnn, newshape=level_shape)\n",
    "    prediction_dense[:, lev, :, :] = np.reshape(unscaled_predict_y_dense, newshape=level_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of predicted values as NetCDF\n",
    "At this point the entire dataset has been predicted and the predicted values are in arrays that we can add to an xarray DataSet that we'll then write as NetCDF. We will first make a copy of the prediction features dataset since this has all the coordinate variables and attributes we'll want in the predicted labels dataset, we'll then remove all data variables before adding the predicted values arrays as new variables to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the prediction features dataset since the predicted label(s) should share the same coordinates, etc.\n",
    "ds_predict_labels = xr.open_dataset(data_dir + \"/fv091x180L26_moist_HS.cam.h1.2001-02-25-00000_lowres.nc\")\n",
    "\n",
    "# remove all non-label data variables from the predictions dataset\n",
    "for var in ds_predict_labels.data_vars:\n",
    "    if var not in labels:\n",
    "        ds_predict_labels = ds_predict_labels.drop(var)\n",
    "\n",
    "# create new variables to contain the predicted labels, assign these into the prediction dataset\n",
    "predicted_label_var = xr.Variable(dims=('time', 'lev', 'lat', 'lon'),\n",
    "                                  data=prediction_cnn,\n",
    "                                  attrs=ds_predict_labels[labels[0]].attrs)\n",
    "ds_predict_labels[labels[0] + \"_cnn\"] = predicted_label_var\n",
    "predicted_label_var = xr.Variable(dims=('time', 'lev', 'lat', 'lon'),\n",
    "                                  data=prediction_dense,\n",
    "                                  attrs=ds_predict_labels[labels[0]].attrs)\n",
    "ds_predict_labels[labels[0] + \"_dense\"] = predicted_label_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create variables to contain the differences between predicted values and those computed by NCAR CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the dataset containing the computed label values corresponding to the input features used for prediction\n",
    "ds_cam_labels = xr.open_dataset(data_dir + \"/fv091x180L26_moist_HS.cam.h1.2001-02-25-00000_lowres.nc\")\n",
    "\n",
    "# get the differences between computed and predicted values\n",
    "pttend_diff_cnn = ds_cam_labels[labels[0]].values - prediction_cnn\n",
    "pttend_diff_dense = ds_cam_labels[labels[0]].values - prediction_dense\n",
    "\n",
    "# create the variables and add to the dataset\n",
    "predicted_label_var = xr.Variable(dims=('time', 'lev', 'lat', 'lon'),\n",
    "                                  data=pttend_diff_cnn,\n",
    "                                  attrs=ds_predict_labels[labels[0]].attrs)\n",
    "ds_predict_labels[labels[0] + \"_cnn_diff\"] = predicted_label_var\n",
    "predicted_label_var = xr.Variable(dims=('time', 'lev', 'lat', 'lon'),\n",
    "                                  data=pttend_diff_dense,\n",
    "                                  attrs=ds_predict_labels[labels[0]].attrs)\n",
    "ds_predict_labels[labels[0] + \"_dense_diff\"] = predicted_label_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output predicted dataset as NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the predicted label(s)' dataset as a NetCDF file\n",
    "ds_predict_labels.to_netcdf(netcdf_predict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot difference for various times/levels\n",
    "We'll use xarray's simple plotting functions to illustrate some of the differences we see at various times and levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dense = ds_predict_labels[labels[0] + \"_dense_diff\"].isel(time=0, lev=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x2ace3be8cfd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "diff_dense.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
